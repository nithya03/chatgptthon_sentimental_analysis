{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "importing libraries "
      ],
      "metadata": {
        "id": "76QB2fGDRmCs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEeJe1FI_hIu"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking if the data has been properly imported"
      ],
      "metadata": {
        "id": "vXQboWXoRqPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "movie_reviews.words()"
      ],
      "metadata": {
        "id": "f52cKXNT_1iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for this code the opposite value/answer is obtained \n",
        "--needs more time to complete"
      ],
      "metadata": {
        "id": "Sculjw8rReFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import random\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "# Step 1: Load the movie reviews dataset\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "random.shuffle(documents)\n",
        "\n",
        "all_words = []\n",
        "for w in movie_reviews.words():\n",
        "    all_words.append(w.lower())\n",
        "all_words = nltk.FreqDist(all_words)\n",
        "word_features = list(all_words.keys())[:3000]\n",
        "\n",
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains(%s)' % word] = (word in document_words)\n",
        "    return features\n",
        "\n",
        "# Step 3: Extract the features\n",
        "featuresets = [(document_features(d), c) for (d, c) in documents]\n",
        "\n",
        "# Step 4: Train the classifier\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "# Step 5: Test the classifier\n",
        "print(nltk.classify.accuracy(classifier, test_set))\n",
        "\n",
        "# Step 6: Classify a new text\n",
        "new_text = \"This movie was great! I loved it.\"\n",
        "print(classifier.classify(document_features(new_text.split())))"
      ],
      "metadata": {
        "id": "4Z2OY5li_5GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "there is no difference i.e the movie reviews dataset seems to not be imported properly (cannot see any difference)"
      ],
      "metadata": {
        "id": "koJMjkzWQ4qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import random\n",
        "from nltk.corpus import movie_reviews\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Step 1: Define a sample text\n",
        "text = input(\"enter comment : \")\n",
        "\n",
        "# Step 2: Analyze the sentiment of the text\n",
        "blob = TextBlob(text)\n",
        "sentiment = blob.sentiment.polarity\n",
        "\n",
        "# Step 3: Classify the sentiment as positive, negative, or neutral\n",
        "if sentiment > 0:\n",
        "    print(\"Positive\")\n",
        "elif sentiment < 0:\n",
        "    print(\"Negative\")\n",
        "else:\n",
        "    print(\"Neutral\")"
      ],
      "metadata": {
        "id": "a2VhmrI9_9k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pyaudio installation in google collaboratory"
      ],
      "metadata": {
        "id": "lVltsXojRLLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg"
      ],
      "metadata": {
        "id": "vaOBxQ-zA57y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyAudio"
      ],
      "metadata": {
        "id": "4ooON5hQA8ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code the pyaudio imports and the input devices have a problem loading in \n",
        "Hence,this code cannot be executed "
      ],
      "metadata": {
        "id": "5MKTYVezQdpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Set up the SpeechRecognition object\n",
        "r = sr.Recognizer()\n",
        "\n",
        "# Record audio from the microphone\n",
        "with sr.Microphone() as source:\n",
        "    print(\"Please speak your sentence:\")\n",
        "    audio = r.listen(source)\n",
        "\n",
        "# Convert audio to text using the SpeechRecognition library\n",
        "text = r.recognize_google(audio)\n",
        "\n",
        "# Analyze sentiment using TextBlob\n",
        "blob = TextBlob(text)\n",
        "sentiment = blob.sentiment.polarity\n",
        "\n",
        "# Print the sentiment score\n",
        "print(\"Sentiment score:\", sentiment)"
      ],
      "metadata": {
        "id": "g-3OQKeHAB0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "go to below code *"
      ],
      "metadata": {
        "id": "x0Rol9MqQ06k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download VADER lexicon\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Load the public reviews dataset\n",
        "reviews_df = pd.read_csv('https://raw.githubusercontent.com/SAP-samples/datahub-dine/main/data/reviews.csv')\n",
        "\n",
        "# Create an instance of the VADER sentiment analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define a function to compute the sentiment score of a given review text\n",
        "def get_sentiment_score(review_text):\n",
        "    sentiment = sia.polarity_scores(review_text)\n",
        "    return sentiment['compound']\n",
        "\n",
        "# Apply the sentiment analyzer to the review texts in the dataset\n",
        "reviews_df['sentiment_score'] = reviews_df[\"Three start. I have some issues like some keys don't work on first instance..and is somewhat slow also\"].apply(get_sentiment_score)\n",
        "\n",
        "# Classify the sentiment of the reviews as positive, neutral, or negative based on the sentiment score\n",
        "def classify_sentiment(sentiment_score):\n",
        "    if sentiment_score > 0:\n",
        "        return 'Positive'\n",
        "    elif sentiment_score < 0:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "reviews_df['sentiment'] = reviews_df['sentiment_score'].apply(classify_sentiment)\n",
        "\n",
        "#give input number of reviews \n",
        "num_reviews = int(input(\"Enter the number of reviews to display: \"))\n",
        "\n",
        "# Print the first 10 reviews and their sentiment scores and classifications\n",
        "print(reviews_df[[\"Three start. I have some issues like some keys don't work on first instance..and is somewhat slow also\", 'sentiment_score', 'sentiment']].head(num_reviews))\n"
      ],
      "metadata": {
        "id": "SEZ4akuLQY7-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}